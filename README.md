# llm-rag-synthetic-data-evaluation
End-to-end RAG system for reliable LLM responses using document retrieval, synthetic data generation, and automated evaluation. Includes vector search, grounded answer generation with citations, hallucination detection, and synthetic Q&amp;A creation to simulate real-world enterprise LLM data and evaluation workflows.

# ğŸ“š RAG Knowledge Assistant (Local, Cost-Free)

An end-to-end Retrieval Augmented Generation (RAG) system built using local embeddings and vector search.  
This project demonstrates how to build reliable LLM-style applications without paid APIs.

---

## ğŸš€ Features

- ğŸ“„ Document ingestion (PDF / TXT)
- âœ‚ï¸ Smart text chunking
- ğŸ§  Local embedding generation (Sentence Transformers)
- ğŸ—„ Vector database (ChromaDB)
- ğŸ” Semantic retrieval
- ğŸ’¬ Context grounded answer generation
- ğŸŒ Streamlit web interface
- ğŸ’° Fully local â€” No OpenAI cost

---

## ğŸ–¥ Demo

![RAG UI Demo](docs/rag_ui_demo.png)

---

## ğŸ§  Architecture

User Question  
â†“  
Retriever (Vector Search)  
â†“  
Relevant Document Chunks  
â†“  
Answer Generator (Grounded Response)  

---

## ğŸ›  Tech Stack

| Component | Tool |
|---|---|
| Language | Python |
| RAG Framework | LangChain |
| Vector DB | ChromaDB |
| Embeddings | Sentence Transformers |
| UI | Streamlit |
| Environment | Python venv |

---

## ğŸ“‚ Project Structure
src/
â”œ ingestion/
â”‚ â”” build_index.py
â”œ retrieval/
â”‚ â”” query_db.py
â”œ rag/
â”‚ â”” simple_rag.py
app/
â”” chat_app.py
data/
â”œ raw_docs/
â”” chroma/
docs/
â”” rag_ui_demo.png


---

## âš™ï¸ Installation

```bash
git clone https://github.com/YOUR_USERNAME/llm-rag-synthetic-data-evaluation.git
cd llm-rag-synthetic-data-evaluation

python3 -m venv venv
source venv/bin/activate

pip install -r requirements.txt


â–¶ï¸ Run Project
Build Vector Database
python src/ingestion/build_index.py
Launch Web App
python -m streamlit run app/chat_app.py


ğŸ“š Example Usage
Ask:
What is RAG?
What does this document say?
ğŸ¯ Why This Project
This project was built to demonstrate:
Data-centric AI thinking
LLM grounding to reduce hallucination
Cost-efficient local LLM infrastructure
Production-style pipeline design
ğŸš€ Future Improvements
Synthetic data generation
Evaluation metrics (faithfulness, hallucination detection)
Chat history memory
Cloud deployment
ğŸ‘©â€ğŸ’» Author
Charan Siddarth

---

# ğŸš€ STEP 3 â€” Push README

```bash
git add README.md
git commit -m "Add professional README documentation"
git push
